<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Mansoor Nasir Cheema</title>

  <meta name="author" content="Mansoor Nasir Cheema">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Mansoor Nasir Cheema
                  </p>
                  <p>
                  <p>I'm a software developer at <a href="https://www.thoughtworks.com/">Thoughtsworks</a> Munich
                    where I focus on design and development of maintainable and well-architectured software. Particularly I am involved in programming ML models, cloud based Microservices, and C++ SDK's for edge devices.
                  </p>
                  <p>
                    I completed MSc. Informatics at <a href="https://www.tum.de">Technical University of Munich</a> where I
                    specialized in Computer Vision and Machine Learning with applications in Robotic Perception and 3D
                    Scene Understanding.
                  </p>
                  <p> Earlier, I was an exchange student at <a href="https://www.tum.de">ETH Zurich</a>
                    where I wrote my Thesis at <a href="https://www.asl.ethz.ch">Autonomous System Lab</a> under the supervision of <a href="https://schmluk.github.io/">Dr. Lukas Schmid</a> 
                    , Dr. Victor Reijgwart and <a
                    href="https://asl.ethz.ch/the-lab/people/person-detail.Mjk5ODE=.TGlzdC8yMDI4LDEyMDExMzk5Mjg=.html">Prof. Roland Siegwart</a>. I'm interested in 3D computer vision and deep learning, particularly 3D dense mapping, scene completion and language vision foundation models for multi-modal spatial intelligence. 
                     
                    <!-- Deep Learnt volumetric mapping for mobile robots. -->
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:mansoorcheema1@gmail.com">Email</a> &nbsp;/&nbsp;
                    <!-- <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp; -->
                    <a href="https://www.linkedin.com/in/mansoor-nasir-cheema/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/mansoorcheema/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/Mansoor.jpg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/Mansoor.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <!-- <p>
                    I'm interested in 3D computer vision, deep learning, and spatial ai with applications on 3D scene
                    understanding and robotic perception.
                  </p> -->
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="pepper_stop()" onmouseover="pepper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='pepper_gif'><img src='images/ssc.gif' width="160" height="120"></div>
                    <img src='images/ssc.jpg' width="160" height="120">
                  </div>
                  <script type="text/javascript">
                    function pepper_start() {
                      document.getElementById('pepper_gif').style.opacity = "1";
                    }
                    function pepper_stop() {
                      document.getElementById('pepper_gif').style.opacity = "0";
                    }
                    pepper_stop()
                  </script>
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href=https://arxiv.org/abs/2208.08307">
                    <span class="papertitle">SC-Explorer: Incremental 3D Scene Completion for Safe and Efficient
                      Exploration Mapping and Planning</span>
                  </a>
                  <br>
                  <a href="https://schmluk.github.io/">Lukas Schmid</a>,
                  <strong>Mansoor Nasir Cheema</strong>,
                  Victor Reijgwart,
                  <a href="https://www.google.com/search?q=Roland+Siegwart">Roland Siegjwart</a>,
                  <a href="https://federicotombari.github.io/">Federico Tombari</a>,
                  Cesar Cadena
                  <br>
                  <em>Preprint</em>, 2022
                  <br>
                  <a href="https://www.youtube.com/watch?v=DMXdhCqUqts">video</a>
                  /
                  <a href="https://github.com/ethz-asl/ssc_exploration">code</a>
                  /
                  <a href="https://arxiv.org/abs/2406.11737">arXiv</a>
                  <p></p>
                  <p>
                    Incrementally fusing 3D semantic scene completions complementing volumetric semantic mapping for safe
                    and efficient autonomous exploration.
                  </p>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/thesis.gif" alt="thesis" width="160" height="120">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="data/Masters_Thesis_ETH.pdf">
                    <span class="papertitle">Leveraging Deep Learnt scene compleiton for fast autonomous exploration
                      mapping and planning</span>
                  </a>
                  <br>
                  <strong>Mansoor Nasir Cheema</strong>
                  <br>
                  <em>MSc. Thesis</em>, ETH Zurich
                  <br>
                  Supervisors: <a href="https://schmluk.github.io/">Lukas Schmid</a>, Victor Reijgwart, <a
                    href="https://federicotombari.github.io/">Federico Tombari</a>, <a
                    href="https://www.google.com/search?q=Roland+Siegwart">Roland Siegjwart</a>
                  <br>
                  <a href="data/Masters_Thesis_ETH.pdf">paper</a> /
                  <a href="https://github.com/mansoorcheema/ssc_3d_planning">code</a>
                  <p></p>
                </td>
              </tr>

            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Teaching</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/tum_logo.png" width="160">
                </td>
                <td width="75%" valign="center">
                  Teaching Assistant, <strong>Hands on Deep Learning</strong>, Summer 2020

                </td>
              </tr>

            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Opensource</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/PyTorch_logo_black.svg"
                    width="160"></td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>Adaptive Log Softmax </strong>
                  </br>
                  Contribution for <em>C++ Neural Network API</em>, PyTorch 1.5.0
                  <br>
                  <a
                    href="https://pytorch.org/cppdocs/api/classtorch_1_1nn_1_1_adaptive_log_softmax_with_loss_impl.html">documentation</a>
                  / <a
                    href="https://github.com/pytorch/pytorch/commit/e95657b87e9c658c1c3a173ffbc6ca2c08849875">code</a> /
                  <a href="https://arxiv.org/abs/1609.04309">reference paper</a>
                  <p> Programmed an efficient approximation of softmax based on <a
                      href="https://arxiv.org/abs/1609.04309">paper</a> by Edouard Grave et al. that scales with very
                    large vocabularies boosting
                    performance of Large Language Models.
                  </p>
                </td>

              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/PyTorch_logo_black.svg"
                    width="160"></td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <strong>Local Resposne Normalization </strong>
                  </br>
                  Contribution for <em>C++ Neural Network API</em>, PyTorch 1.4.0
                  <br>
                  <a
                    href="https://pytorch.org/cppdocs/api/classtorch_1_1nn_1_1_local_response_norm_impl.html">documentation</a>
                  / <a
                    href="https://github.com/pytorch/pytorch/commit/a465b033fdb35e746aba3df5debcacc26c44555c">code</a>
                  <p> Programmed local response normalization activation layer along with the unit tests
                  </p>
                </td>

              </tr>


            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Adapted from <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
